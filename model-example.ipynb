{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model sizes example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 190, 1000])\n",
      "Output size of conv1: torch.Size([1, 64, 62, 1000])\n",
      "Output size of conv2: torch.Size([1, 128, 20, 1000])\n",
      "Output size of adaptivemaxpool: torch.Size([1, 128, 20, 1])\n",
      "Output size after flatten: torch.Size([1, 2560])\n",
      "Output size of fc encoder: torch.Size([1, 2])\n",
      "Output size of fc decoder: torch.Size([1, 2560])\n",
      "Output size after unflatten: torch.Size([1, 128, 20, 1])\n",
      "Output size after adaptivemaxpool: torch.Size([1, 128, 20, 1000])\n",
      "Output size of conv2: torch.Size([1, 64, 62, 1000])\n",
      "Output size of conv1: torch.Size([1, 1, 190, 1000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Summary of the Encoder model sizes\n",
    "input = torch.randn(1, 1, 190, 1000)\n",
    "print(input.shape)\n",
    "\n",
    "#==========ENCODER=================\n",
    "m = nn.Conv2d(1, 64, (7,5), stride=(3,1), padding=(1,2))\n",
    "output = m(input)\n",
    "print('Output size of conv1:', output.shape)\n",
    "\n",
    "m1 = nn.Conv2d(64, 128, (5,3), stride=(3,1), padding=(1,1))\n",
    "output1 = m1(output)\n",
    "print('Output size of conv2:', output1.shape)\n",
    "\n",
    "m2 = nn.AdaptiveMaxPool2d((20, 1), return_indices=True)\n",
    "output2, indices2 = m2(output1)\n",
    "print('Output size of adaptivemaxpool:', output2.shape)\n",
    "\n",
    "output3 = output2.view(output2.size(0), -1)\n",
    "print('Output size after flatten:', output3.shape)\n",
    "\n",
    "m4 = nn.Linear(64*2*20, 2)\n",
    "output4 = m4(output3)\n",
    "print('Output size of fc encoder:', output4.shape)\n",
    "\n",
    "\n",
    "#==========DECODER=================\n",
    "m5 = nn.Linear(2, 64*2*20)\n",
    "output5 = m5(output4)\n",
    "print('Output size of fc decoder:', output5.shape)\n",
    "\n",
    "output6 = output5.view(output5.size(0), 64*2, 20, -1)\n",
    "print('Output size after unflatten:', output6.shape)\n",
    "\n",
    "m7 = nn.AdaptiveMaxPool2d((20, input.shape[3]))\n",
    "output7 = m7(output6)\n",
    "print('Output size after adaptivemaxpool:', output7.shape)\n",
    "\n",
    "m8 = nn.ConvTranspose2d(128, 64, (5,3), stride=(3,1), padding=(2,1), dilation=(2,1))\n",
    "output8 = m8(output7)\n",
    "print('Output size of conv2:', output8.shape)\n",
    "\n",
    "m9 = nn.ConvTranspose2d(64, 1, (7,5), stride=(3,1), padding=(3,2), dilation=(2,1))\n",
    "output9 = m9(output8)\n",
    "print('Output size of conv1:', output9.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
